{% extends 'base.html' %}

{% block title %}q2-sample-classifier : {{ title }}{% endblock %}

{% block fixed %}{% endblock %}

{% block content %}

<div class="row">
  {% if predictions %}
  <h1>Model Accuracy</h1>
  {% endif %}
  <div class="text-center">
    {% if predictions %}
    <a href="predictions.pdf">
      <img src="predictions.png">
      <br>
      <p>Download as PDF</p>
    </a>
    {% endif %}
    {% if predictions %}
    <div class="col-lg-12">
      {{ predictions }}
      <a href="predictive_accuracy.tsv">
        <p>Download accuracy results as tsv</p>
      </a>
    </div>
    {% endif %}
    {% if roc %}
    <div class="col-lg-12">
      <h1>Receiver Operating Characteristic Curves</h1>
      <a href="roc_plot.pdf">
        <img src="roc_plot.png">
        <br>
        <p>Download as PDF</p>
      </a>
      <div class="text-justify">
        <p>Receiver Operating Characteristic (ROC) curves are a graphical
        representation of the classification accuracy of a machine-learning
        model. The ROC curve plots the relationship between the true positive
        rate (TPR, on the y-axis) and the false positive rate (FPR, on the
        x-axis) at various threshold settings. Thus, the top-left corner of the
        plot represents the "optimal" performance position, indicating a FPR
        of zero and a TPR of one. This "optimal" scenario is unlikely to occur
        in practice, but a greater area under the curve (AUC) indicates better
        performance. This can be compared to the error rate achieved by random
        chance, which is represented here as a diagonal line extending from the
        lower-left to upper-right corners. Additionally, the "steepness" of the
        curve is important, as a good classifier should maximize the TPR while
        minimizing the FPR.

        In addition to showing the ROC curves for each class, average ROCs and
        AUCs are calculated. "Micro-averaging" calculates metrics globally by
        averaging across each sample; hence class imbalance impacts this metric.
        "Macro-averaging" is another average metric, which gives equal weight to
        the classification of each sample.</p>
      </div>
    </div>
    {% endif %}
    {% if optimize_feature_selection %}
    <h1>Recursive feature extraction</h1>
    <div class="text-center">
      <a href="rfe_plot.pdf">
        <img src="rfe_plot.png">
        <br>
        <p>Download as PDF</p>
      </a>
      <a href="rfe_scores.tsv">
        <p>Download as TSV</p>
      </a>
    </div>
    {% endif %}
    {% if result %}
    <h1>Model parameters</h1>
    <div class="col-lg-12">
      {{ result }}
    </div>
    {% endif %}
  </div>
</div>

{% endblock %}
